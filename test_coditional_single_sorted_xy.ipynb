{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from model import SingleTransformer\n",
    "from dataset import SingleTransformerDataset\n",
    "import os \n",
    "import numpy as np\n",
    "import shutil\n",
    "from sim import simulate_mechanism\n",
    "from utils import preprocess_curves\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/home/anurizada/Documents/nobari_10_transformer\"\n",
    "# adj = np.load(os.path.join(data_dir, \"adjacency.npy\"), mmap_mode='r')\n",
    "# print(adj.shape)\n",
    "# print(adj[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_ddp_model(model, checkpoint_path, strict=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Load model weights from checkpoint, handling DDP wrapping if present.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to load weights into\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        clip_loss_fn: Optional CLIP loss function to load weights for\n",
    "        strict: Whether to strictly enforce matching keys between model and checkpoint\n",
    "        verbose: Whether to print debugging information\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, checkpoint) with loaded weights\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load checkpoint with error handling\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        if verbose:\n",
    "            print(f\"‚úÖ Checkpoint loaded from {checkpoint_path}\")\n",
    "            print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "            # print(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Extract state dict\n",
    "        state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "        \n",
    "        # Remove DDP wrapper prefixes\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "            new_state_dict[new_key] = v\n",
    "            if verbose and k != new_key:\n",
    "                print(f\"‚ö†Ô∏è Renamed DDP key: {k} -> {new_key}\")\n",
    "        \n",
    "        # Verify model architecture matches checkpoint\n",
    "        model_keys = set(model.state_dict().keys())\n",
    "        ckpt_keys = set(new_state_dict.keys())\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nüîç Model vs Checkpoint Key Analysis:\")\n",
    "            print(f\"Model has {len(model_keys)} keys\")\n",
    "            print(f\"Checkpoint has {len(ckpt_keys)} keys\")\n",
    "            \n",
    "            missing_in_model = ckpt_keys - model_keys\n",
    "            missing_in_ckpt = model_keys - ckpt_keys\n",
    "            \n",
    "            if missing_in_model:\n",
    "                print(f\"\\n‚ùå Keys in checkpoint but not in model: {missing_in_model}\")\n",
    "            if missing_in_ckpt:\n",
    "                print(f\"\\n‚ùå Keys in model but not in checkpoint: {missing_in_ckpt}\")\n",
    "        \n",
    "        # Load model weights with error handling\n",
    "        try:\n",
    "            model.load_state_dict(new_state_dict, strict=strict)\n",
    "            if verbose:\n",
    "                print(\"\\n‚úÖ Model weights loaded successfully!\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"\\n‚ùå Error loading model weights: {str(e)}\")\n",
    "            if not strict:\n",
    "                print(\"‚ö†Ô∏è Attempting partial load (strict=False)\")\n",
    "                model.load_state_dict(new_state_dict, strict=False)\n",
    "        \n",
    "        return model, checkpoint\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load checkpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Model Configuration\n",
    "model_config = {\n",
    "    'output_size': 2,\n",
    "    'tgt_seq_len': 10,\n",
    "    'd_model': 1024,\n",
    "    'h': 32,\n",
    "    'N': 6\n",
    "}\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "\n",
    "# Initialize Model\n",
    "model = SingleTransformer(\n",
    "    output_size=model_config['output_size'],\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N']\n",
    ").to(device)\n",
    "\n",
    "\n",
    "model, checkpoint = load_ddp_model(model, f\"weights/x_y_weights/d{model_config['d_model']}_h{model_config['h']}_n{model_config['N']}_bs{batch_size}_lr{lr}_best.pth\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SingleTransformerDataset(\n",
    "        data_dir='/home/anurizada/Documents/nobari_10_transformer',\n",
    "    )\n",
    "data_loader = DataLoader(dataset, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_conditional(model, source, adj_type, max_len, eos_token=torch.tensor([1.0, 1.0])):\n",
    "    model, source = model.to(device), source.to(device)\n",
    "    adj_type = adj_type.to(device)\n",
    "\n",
    "    # print(source.shape, adj_type.shape)\n",
    "\n",
    "    # Encode the source once\n",
    "    encoder_output, curve_emb, adj_emb = model.encode(source, adj_type)\n",
    "\n",
    "    # Initialize decoder input with start token\n",
    "    decoder_input = torch.ones(1, 1, 2).to(device) * -2.0  # Start token\n",
    "    \n",
    "    while decoder_input.size(1) < max_len:\n",
    "        # Build causal mask (0 for allowed, -inf for blocked)\n",
    "        decoder_mask = causal_mask(decoder_input.size(1), device)\n",
    "\n",
    "        # Decode\n",
    "        decoder_output = model.decode(\n",
    "            encoder_output,\n",
    "            None,\n",
    "            decoder_input,\n",
    "            decoder_mask\n",
    "        )\n",
    "        \n",
    "        proj_output = model.projection(model.projection_norm(decoder_output))\n",
    "        \n",
    "        # Get next token\n",
    "        next_token = proj_output[:, -1].unsqueeze(1)\n",
    "        print(next_token)\n",
    "        # EOS check\n",
    "        if torch.allclose(next_token.squeeze(), eos_token.to(device), atol=1e-1):\n",
    "            break\n",
    "\n",
    "        # Append token\n",
    "        decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "\n",
    "    return decoder_input.squeeze(0), curve_emb, adj_emb\n",
    "\n",
    "\n",
    "def causal_mask(size, device):\n",
    "    # (n, n) upper-triangular boolean mask\n",
    "    mask = torch.triu(torch.ones(size, size, device=device), diagonal=1).bool()\n",
    "    # Add batch dimension -> (1, n, n)\n",
    "    return mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    results_dir = f\"xy_d{model_config['d_model']}_h{model_config['h']}_n{model_config['N']}_bs{batch_size}_lr{lr}\"\n",
    "    max_mech_size = 10\n",
    "    num_conditions = 200  # Number of different adjacency conditions to test per curve\n",
    "    prefix_rows = np.array([[0.5, 0.5], [0.6, 0.5]], dtype=np.float32)\n",
    "    plt_style = {\n",
    "        'truth_joints': {'color': 'red', 'marker': 'o', 's': 60, 'label': 'Truth Joints'},\n",
    "        'pred_joints': {'color': 'blue', 'marker': 'x', 's': 60, 'label': 'Pred Joints'},\n",
    "        'truth_curve': {'color': 'magenta', 'linestyle': '-', 'linewidth': 3, 'label': 'Truth Curve'},\n",
    "        'pred_curve': {'color': 'cyan', 'linestyle': '-', 'linewidth': 2, 'label': 'Predicted Curve'},\n",
    "        'cond_curve': {'color': 'green', 'linestyle': '--', 'linewidth': 2, 'label': 'Condition Curve'}\n",
    "    }\n",
    "\n",
    "# Invalid joint values to remove\n",
    "INVALID_JOINTS = np.array([\n",
    "    [-1.0, -1.0],\n",
    "    [1.0,  1.0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device).float()  # assume `model` is already defined elsewhere\n",
    "\n",
    "@contextmanager\n",
    "def managed_figure(figsize=(10, 8)):\n",
    "    \"\"\"Context manager to ensure figures are properly cleaned up\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    try:\n",
    "        yield ax\n",
    "    finally:\n",
    "        plt.close(fig)\n",
    "\n",
    "def prepare_results_dir():\n",
    "    \"\"\"Prepare clean results directory\"\"\"\n",
    "    if os.path.exists(Config.results_dir):\n",
    "        shutil.rmtree(Config.results_dir)\n",
    "    os.makedirs(Config.results_dir, exist_ok=True)\n",
    "\n",
    "def process_adjacency(adj_tensor):\n",
    "    \"\"\"Convert raw adjacency to simulation format (handles both tensors and numpy arrays)\"\"\"\n",
    "    if isinstance(adj_tensor, torch.Tensor):\n",
    "        adj = adj_tensor.detach().cpu().squeeze().float().numpy()\n",
    "    elif isinstance(adj_tensor, np.ndarray):\n",
    "        adj = adj_tensor.squeeze().astype(np.float32)\n",
    "    else:\n",
    "        raise TypeError(f\"Input must be torch.Tensor or numpy.ndarray, got {type(adj_tensor)}\")\n",
    "\n",
    "    valid_mask = ~np.all(adj == 0, axis=1)\n",
    "    adj = adj[valid_mask][:, valid_mask]\n",
    "    node_types = np.diag(adj).astype(bool)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "    return adj.astype(np.float32), node_types\n",
    "\n",
    "def simulate(adj, joints, node_types):\n",
    "    \"\"\"Run simulation with error handling\"\"\"\n",
    "    try:\n",
    "        if adj.dtype != np.float32:\n",
    "            adj = adj.astype(np.float32)\n",
    "        if joints.dtype != np.float32:\n",
    "            joints = joints.astype(np.float32)\n",
    "        \n",
    "        result = simulate_mechanism(adj, joints, node_types)\n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        trajectory = torch.tensor(result[-1], dtype=torch.float32).unsqueeze(0)\n",
    "        return preprocess_curves(trajectory).detach().cpu().numpy().squeeze()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_joints(pred_sequence):\n",
    "    \"\"\"Prepare joint positions from single decoder output\"\"\"\n",
    "    # Remove start token and EOS token if present\n",
    "    joints = pred_sequence[1:].detach().cpu().float()\n",
    "    return np.concatenate([Config.prefix_rows, joints.numpy()], axis=0)\n",
    "\n",
    "def save_plot(ax, curve_dir, filename, title=None):\n",
    "    \"\"\"Helper function to save plots with guaranteed cleanup\"\"\"\n",
    "    try:\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(curve_dir, filename))\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def filter_invalid_joints(joints: np.ndarray, invalid_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Remove any row in `joints` that exactly matches any row in `invalid_values`.\"\"\"\n",
    "    mask = np.ones(len(joints), dtype=bool)\n",
    "    for invalid in invalid_values:\n",
    "        mask &= ~np.all(joints == invalid, axis=1)\n",
    "    return joints[mask]\n",
    "\n",
    "def create_curve_plot(ax, truth_joints, pred_joints, gt_curve=None, pred_curve=None, \n",
    "                     cond_curve=None, title=None):\n",
    "    \"\"\"Create a standardized plot with joint enumeration\"\"\"\n",
    "    try:\n",
    "        if gt_curve is not None:\n",
    "            ax.plot(gt_curve[:, 0], gt_curve[:, 1], **Config.plt_style['truth_curve'])\n",
    "        if pred_curve is not None:\n",
    "            ax.plot(pred_curve[:, 0], pred_curve[:, 1], **Config.plt_style['pred_curve'])\n",
    "        if cond_curve is not None:\n",
    "            ax.plot(cond_curve[:, 0], cond_curve[:, 1], **Config.plt_style['cond_curve'])\n",
    "        \n",
    "        # Scatter points\n",
    "        ax.scatter(truth_joints[:, 0], truth_joints[:, 1], **Config.plt_style['truth_joints'])\n",
    "        ax.scatter(pred_joints[:, 0], pred_joints[:, 1], **Config.plt_style['pred_joints'])\n",
    "\n",
    "        # Annotate truth joints\n",
    "        for idx, (x, y) in enumerate(truth_joints):\n",
    "            ax.annotate(str(idx), (x, y), textcoords=\"offset points\", xytext=(5,5), fontsize=8, color=\"red\")\n",
    "\n",
    "        # Annotate predicted joints\n",
    "        for idx, (x, y) in enumerate(pred_joints):\n",
    "            ax.annotate(str(idx), (x, y), textcoords=\"offset points\", xytext=(5,-10), fontsize=8, color=\"blue\")\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def compute_all_adj_embeddings(model, unique_adjs, curve_data, device):\n",
    "    \"\"\"Compute and cache embeddings for all candidate adjacencies.\"\"\"\n",
    "    all_adj_embs = []\n",
    "    with torch.no_grad():\n",
    "        for cond_adj in tqdm(unique_adjs, desc=\"Caching adjacency embeddings\"):\n",
    "            cond_adj_tensor = torch.from_numpy(cond_adj).to(device).float().unsqueeze(0)\n",
    "            _, _, cond_adj_emb = model.encode(curve_data, cond_adj_tensor)\n",
    "\n",
    "            # (1,1,1024) -> (1024,)\n",
    "            cond_adj_emb = cond_adj_emb.squeeze(0).squeeze(0)\n",
    "            all_adj_embs.append(cond_adj_emb)\n",
    "\n",
    "    # [M, 1024]\n",
    "    all_adj_embs = torch.stack(all_adj_embs, dim=0)\n",
    "    all_adj_embs = F.normalize(all_adj_embs, p=2, dim=-1)\n",
    "    return all_adj_embs\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Main processing\n",
    "# ---------------------------\n",
    "prepare_results_dir()\n",
    "unique_adjs = np.load(\"unique_adjacency_matrices.npy\")\n",
    "print(f\"Loaded {len(unique_adjs)} unique adjacency matrices\")\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "    if batch_idx == 50:\n",
    "        break\n",
    "\n",
    "    # Create subfolder for this curve\n",
    "    curve_dir = os.path.join(Config.results_dir, f'curve_{batch_idx}')\n",
    "    os.makedirs(curve_dir, exist_ok=True)\n",
    "\n",
    "    # Prepare data\n",
    "    curve_data = batch[\"curve_numerical\"].to(device).float()\n",
    "    gt_adj = batch[\"adjacency\"].to(device).float()\n",
    "\n",
    "    # Get ground truth joints\n",
    "    truth_joints = batch[\"label\"].view(-1, 2)[:-1].detach().cpu().float()  # Remove EOS token\n",
    "    truth_joints = np.concatenate([Config.prefix_rows, truth_joints.numpy()], axis=0)\n",
    "\n",
    "    # Process ground truth adjacency\n",
    "    gt_adj_processed, gt_node_types = process_adjacency(gt_adj)\n",
    "\n",
    "    # Get prediction with ground truth adjacency\n",
    "    with torch.no_grad():\n",
    "        pred_sequence, curve_emb, gt_adj_emb = greedy_decode_conditional(\n",
    "            model, curve_data, gt_adj, Config.max_mech_size\n",
    "        )\n",
    "\n",
    "    # (1,1,1024) -> (1,1024)\n",
    "    curve_emb = curve_emb.squeeze(0).squeeze(0).unsqueeze(0)  # [1,1024]\n",
    "    curve_emb = F.normalize(curve_emb, p=2, dim=-1)\n",
    "\n",
    "    # Prediction joints\n",
    "    pred_joints = get_joints(pred_sequence)\n",
    "    pred_joints = filter_invalid_joints(pred_joints, INVALID_JOINTS)\n",
    "    truth_joints = filter_invalid_joints(truth_joints, INVALID_JOINTS)\n",
    "\n",
    "    gt_curve = simulate(gt_adj_processed, truth_joints, gt_node_types)\n",
    "    pred_curve = simulate(gt_adj_processed, pred_joints, gt_node_types)\n",
    "\n",
    "    # Plot GT vs Pred\n",
    "    with managed_figure() as ax:\n",
    "        create_curve_plot(\n",
    "            ax, truth_joints, pred_joints,\n",
    "            gt_curve=gt_curve, pred_curve=pred_curve,\n",
    "            title=f'Curve {batch_idx}: GT vs Pred'\n",
    "        )\n",
    "        save_plot(ax, curve_dir, f'gt_vs_pred_sim.png')\n",
    "\n",
    "    # ---------------------------\n",
    "    # Step 2: Compare against all adjacencies\n",
    "    # ---------------------------\n",
    "    all_adj_embs = compute_all_adj_embeddings(model, unique_adjs[:Config.num_conditions], curve_data, device)\n",
    "\n",
    "    # Similarity [1,1024] @ [1024,M] -> [M]\n",
    "    sims = (curve_emb @ all_adj_embs.T).squeeze(0)\n",
    "\n",
    "    # Top-k candidates\n",
    "    topk_vals, topk_idx = sims.topk(20)\n",
    "\n",
    "    for rank, (sim_val, cond_idx) in enumerate(zip(topk_vals.tolist(), topk_idx.tolist())):\n",
    "        cond_adj = unique_adjs[cond_idx]\n",
    "        cond_adj_tensor = torch.from_numpy(cond_adj).to(device).float().unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():          \n",
    "            cond_sequence, _, _ = greedy_decode_conditional(\n",
    "                model, curve_data, cond_adj_tensor, Config.max_mech_size\n",
    "            )\n",
    "\n",
    "        cond_joints = get_joints(cond_sequence)\n",
    "        cond_joints = filter_invalid_joints(cond_joints, INVALID_JOINTS)\n",
    "        cond_adj_processed, cond_node_types = process_adjacency(cond_adj)\n",
    "        cond_curve = simulate(cond_adj_processed, cond_joints, cond_node_types)\n",
    "\n",
    "        if cond_curve is None:\n",
    "            continue\n",
    "\n",
    "        with managed_figure() as ax:\n",
    "            create_curve_plot(\n",
    "                ax, truth_joints, cond_joints,\n",
    "                gt_curve=gt_curve, cond_curve=cond_curve,\n",
    "                title=f'Curve {batch_idx} CondRank {rank} (sim={sim_val:.4f})'\n",
    "            )\n",
    "            save_plot(ax, curve_dir, f'cond_rank_{rank}_sim_{sim_val:.4f}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Track unique matrices and their counts\n",
    "# unique_matrices = {}  # {hash_key: (matrix, count)}\n",
    "# counts = defaultdict(int)\n",
    "\n",
    "# for batch in tqdm(data_loader):\n",
    "#     gt_adj = batch[\"adjacency\"].float().cpu()  # Original matrices\n",
    "    \n",
    "#     for matrix in gt_adj:\n",
    "#         # Convert to numpy and create hashable key\n",
    "#         np_matrix = matrix.numpy()\n",
    "#         matrix_key = tuple(np_matrix.round(4).flatten())  # Round to avoid float precision issues\n",
    "        \n",
    "#         # Store first occurrence and count\n",
    "#         if matrix_key not in unique_matrices:\n",
    "#             unique_matrices[matrix_key] = np_matrix\n",
    "#         counts[matrix_key] += 1\n",
    "\n",
    "# # Save all unique matrices in one file\n",
    "# all_matrices = np.stack(list(unique_matrices.values()))\n",
    "# np.save(\"unique_adjacency_matrices.npy\", all_matrices)\n",
    "\n",
    "# print(f\"Saved {len(unique_matrices)} unique matrices\")\n",
    "# print(f\"Output shape: {all_matrices.shape}\")  # e.g. (25, 10, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

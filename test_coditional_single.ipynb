{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 16:28:10.622293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755548890.640250 3311990 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755548890.646056 3311990 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755548890.660992 3311990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755548890.661017 3311990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755548890.661019 3311990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755548890.661021 3311990 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-18 16:28:10.664988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from model import SingleTransformer\n",
    "from dataset import SingleTransformerDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import shutil\n",
    "from sim import simulate_mechanism\n",
    "from utils import preprocess_curves\n",
    "import random \n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPContrastiveLoss(nn.Module):\n",
    "    def __init__(self, init_scale=1/0.07):\n",
    "        super().__init__()\n",
    "        self.logit_scale = nn.Parameter(torch.log(torch.tensor(init_scale)))\n",
    "\n",
    "    def forward(self, image_embeddings, text_embeddings):\n",
    "        image_embeddings = F.normalize(image_embeddings.squeeze(), p=2, dim=1)\n",
    "        text_embeddings = F.normalize(text_embeddings.squeeze(), p=2, dim=1)\n",
    "\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits = logit_scale * image_embeddings @ text_embeddings.t()\n",
    "\n",
    "        N = logits.shape[0]\n",
    "        targets = torch.arange(N, device=logits.device)\n",
    "\n",
    "        loss_i2t = F.cross_entropy(logits, targets)\n",
    "        loss_t2i = F.cross_entropy(logits.t(), targets)\n",
    "        return (loss_i2t + loss_t2i) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Checkpoint loaded from weights/new_model/d1024_h32_n6_bs1024_lr0.0002_best.pth\n",
      "Checkpoint keys: ['model_state_dict', 'optimizer_state_dict', 'clip_loss_state_dict', 'epoch', 'best_loss', 'batch_size', 'learning_rate', 'model_config']\n",
      "\n",
      "üîç Model vs Checkpoint Key Analysis:\n",
      "Model has 807 keys\n",
      "Checkpoint has 807 keys\n",
      "\n",
      "‚úÖ Model weights loaded successfully!\n",
      "‚úÖ CLIP loss function weights loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SingleTransformer(\n",
       "  (encoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder_positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (tgt_embed): InputEmbeddings(\n",
       "    (embedding): Linear(in_features=2, out_features=1024, bias=False)\n",
       "  )\n",
       "  (encoder): ModuleList(\n",
       "    (0-5): 6 x Encoder(\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (feed_forward): FeedForwardBlock(\n",
       "        (w1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "        (w2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (w3): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (final_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0-5): 6 x Decoder(\n",
       "      (self_attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (cross_attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attention_norm): RMSNorm()\n",
       "      (cross_attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (final_norm): RMSNorm()\n",
       "      (feed_forward): FeedForwardBlock(\n",
       "        (w1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "        (w2): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (w3): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projection): Linear(in_features=1024, out_features=2, bias=False)\n",
       "  (projection_norm): RMSNorm()\n",
       "  (contrastive_curve): ContrastiveEncoder(\n",
       "    (convnet): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (projector): ProjectionHead(\n",
       "      (fc1): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "      (rm1): RMSNorm()\n",
       "      (act1): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      (rm2): RMSNorm()\n",
       "      (act2): SiLU()\n",
       "      (fc_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (contrastive_adj): ContrastiveEncoder(\n",
       "    (convnet): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (projector): ProjectionHead(\n",
       "      (fc1): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "      (rm1): RMSNorm()\n",
       "      (act1): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      (rm2): RMSNorm()\n",
       "      (act2): SiLU()\n",
       "      (fc_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_ddp_model(model, checkpoint_path, clip_loss_fn=None, strict=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Load model weights from checkpoint, handling DDP wrapping if present.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to load weights into\n",
    "        checkpoint_path: Path to the checkpoint file\n",
    "        clip_loss_fn: Optional CLIP loss function to load weights for\n",
    "        strict: Whether to strictly enforce matching keys between model and checkpoint\n",
    "        verbose: Whether to print debugging information\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, checkpoint) with loaded weights\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load checkpoint with error handling\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        if verbose:\n",
    "            print(f\"‚úÖ Checkpoint loaded from {checkpoint_path}\")\n",
    "            print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "            # print(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Extract state dict\n",
    "        state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "        \n",
    "        # Remove DDP wrapper prefixes\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "            new_state_dict[new_key] = v\n",
    "            if verbose and k != new_key:\n",
    "                print(f\"‚ö†Ô∏è Renamed DDP key: {k} -> {new_key}\")\n",
    "        \n",
    "        # Verify model architecture matches checkpoint\n",
    "        model_keys = set(model.state_dict().keys())\n",
    "        ckpt_keys = set(new_state_dict.keys())\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nüîç Model vs Checkpoint Key Analysis:\")\n",
    "            print(f\"Model has {len(model_keys)} keys\")\n",
    "            print(f\"Checkpoint has {len(ckpt_keys)} keys\")\n",
    "            \n",
    "            missing_in_model = ckpt_keys - model_keys\n",
    "            missing_in_ckpt = model_keys - ckpt_keys\n",
    "            \n",
    "            if missing_in_model:\n",
    "                print(f\"\\n‚ùå Keys in checkpoint but not in model: {missing_in_model}\")\n",
    "            if missing_in_ckpt:\n",
    "                print(f\"\\n‚ùå Keys in model but not in checkpoint: {missing_in_ckpt}\")\n",
    "        \n",
    "        # Load model weights with error handling\n",
    "        try:\n",
    "            model.load_state_dict(new_state_dict, strict=strict)\n",
    "            if verbose:\n",
    "                print(\"\\n‚úÖ Model weights loaded successfully!\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"\\n‚ùå Error loading model weights: {str(e)}\")\n",
    "            if not strict:\n",
    "                print(\"‚ö†Ô∏è Attempting partial load (strict=False)\")\n",
    "                model.load_state_dict(new_state_dict, strict=False)\n",
    "        \n",
    "        # Handle CLIP loss function if provided\n",
    "        if clip_loss_fn is not None:\n",
    "            if \"clip_loss_state_dict\" in checkpoint:\n",
    "                clip_state_dict = checkpoint[\"clip_loss_state_dict\"]\n",
    "                new_clip_state_dict = {}\n",
    "                for k, v in clip_state_dict.items():\n",
    "                    new_key = k.replace(\"module.\", \"\") if k.startswith(\"module.\") else k\n",
    "                    new_clip_state_dict[new_key] = v\n",
    "                \n",
    "                try:\n",
    "                    clip_loss_fn.load_state_dict(new_clip_state_dict)\n",
    "                    if verbose:\n",
    "                        print(\"‚úÖ CLIP loss function weights loaded successfully!\")\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"‚ùå Error loading CLIP weights: {str(e)}\")\n",
    "            elif verbose:\n",
    "                print(\"‚ö†Ô∏è No CLIP loss weights found in checkpoint\")\n",
    "        \n",
    "        return model, checkpoint\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load checkpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Model Configuration\n",
    "model_config = {\n",
    "    'output_size': 2,\n",
    "    'tgt_seq_len': 10,\n",
    "    'd_model': 1024,\n",
    "    'h': 32,\n",
    "    'N': 6\n",
    "}\n",
    "\n",
    "# Initialize Model\n",
    "model = SingleTransformer(\n",
    "    output_size=model_config['output_size'],\n",
    "    tgt_seq_len=model_config['tgt_seq_len'],\n",
    "    d_model=model_config['d_model'],\n",
    "    h=model_config['h'],\n",
    "    N=model_config['N']\n",
    ").to(device)\n",
    "\n",
    "clip_loss_fn = CLIPContrastiveLoss().to(device)\n",
    "\n",
    "model, checkpoint = load_ddp_model(model, f\"weights/new_model/d{model_config['d_model']}_h{model_config['h']}_n{model_config['N']}_bs1024_lr0.0002_best.pth\", clip_loss_fn)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SingleTransformerDataset(\n",
    "        data_dir='/home/anurizada/Documents/nobari_10_transformer',\n",
    "    )\n",
    "data_loader = DataLoader(dataset, shuffle=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_conditional(model, source, adj_type, max_len, eos_token=torch.tensor([1.0, 1.0])):\n",
    "    model, source = model.to(device), source.to(device)\n",
    "    adj_type = adj_type.to(device)\n",
    "\n",
    "    # Encode the source once\n",
    "    encoder_output, curve_emb, adj_emb = model.encode(source, adj_type)\n",
    "\n",
    "    # Initialize decoder input with start token\n",
    "    decoder_input = torch.ones(1, 1, 2).to(device) * -2.0  # Start token\n",
    "    \n",
    "    while decoder_input.size(1) < max_len:\n",
    "        # Build causal mask (0 for allowed, -inf for blocked)\n",
    "        decoder_mask = causal_mask(decoder_input.size(1), device)\n",
    "\n",
    "        # Decode\n",
    "        decoder_output = model.decode(\n",
    "            encoder_output,\n",
    "            None,\n",
    "            decoder_input,\n",
    "            decoder_mask\n",
    "        )\n",
    "        \n",
    "        proj_output = model.projection(model.projection_norm(decoder_output))\n",
    "        \n",
    "        # Get next token\n",
    "        next_token = proj_output[:, -1].unsqueeze(1)\n",
    "        \n",
    "        # EOS check\n",
    "        if torch.allclose(next_token.squeeze(), eos_token.to(device), atol=1e-1):\n",
    "            break\n",
    "\n",
    "        # Append token\n",
    "        decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "\n",
    "    return decoder_input.squeeze(0), curve_emb, adj_emb\n",
    "\n",
    "\n",
    "def causal_mask(size, device):\n",
    "    # (n, n) upper-triangular boolean mask\n",
    "    mask = torch.triu(torch.ones(size, size, device=device), diagonal=1).bool()\n",
    "    # Add batch dimension -> (1, n, n)\n",
    "    return mask.unsqueeze(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 54507 unique adjacency matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2257251 [04:01<15119:19:47, 24.11s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    results_dir = '1024_dim_h_32_results_clip_bs_1024_new'\n",
    "    max_mech_size = 10\n",
    "    num_conditions = 200  # Number of different adjacency conditions to test per curve\n",
    "    prefix_rows = np.array([[0.5, 0.5], [0.6, 0.5]], dtype=np.float32)\n",
    "    plt_style = {\n",
    "        'truth_joints': {'color': 'red', 'marker': 'o', 's': 60, 'label': 'Truth Joints'},\n",
    "        'pred_joints': {'color': 'blue', 'marker': 'x', 's': 60, 'label': 'Pred Joints'},\n",
    "        'truth_curve': {'color': 'magenta', 'linestyle': '-', 'linewidth': 3, 'label': 'Truth Curve'},\n",
    "        'pred_curve': {'color': 'cyan', 'linestyle': '-', 'linewidth': 2, 'label': 'Predicted Curve'},\n",
    "        'cond_curve': {'color': 'green', 'linestyle': '--', 'linewidth': 2, 'label': 'Condition Curve'}\n",
    "    }\n",
    "\n",
    "# Invalid joint values to remove\n",
    "INVALID_JOINTS = np.array([\n",
    "    [-1.0, -1.0],\n",
    "    [1.0,  1.0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device).float()  # assume `model` is already defined elsewhere\n",
    "\n",
    "@contextmanager\n",
    "def managed_figure(figsize=(10, 8)):\n",
    "    \"\"\"Context manager to ensure figures are properly cleaned up\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    try:\n",
    "        yield ax\n",
    "    finally:\n",
    "        plt.close(fig)\n",
    "\n",
    "def prepare_results_dir():\n",
    "    \"\"\"Prepare clean results directory\"\"\"\n",
    "    if os.path.exists(Config.results_dir):\n",
    "        shutil.rmtree(Config.results_dir)\n",
    "    os.makedirs(Config.results_dir, exist_ok=True)\n",
    "\n",
    "def process_adjacency(adj_tensor):\n",
    "    \"\"\"Convert raw adjacency to simulation format (handles both tensors and numpy arrays)\"\"\"\n",
    "    if isinstance(adj_tensor, torch.Tensor):\n",
    "        adj = adj_tensor.detach().cpu().squeeze().float().numpy()\n",
    "    elif isinstance(adj_tensor, np.ndarray):\n",
    "        adj = adj_tensor.squeeze().astype(np.float32)\n",
    "    else:\n",
    "        raise TypeError(f\"Input must be torch.Tensor or numpy.ndarray, got {type(adj_tensor)}\")\n",
    "\n",
    "    valid_mask = ~np.all(adj == 0, axis=1)\n",
    "    adj = adj[valid_mask][:, valid_mask]\n",
    "    node_types = np.diag(adj).astype(bool)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "    return adj.astype(np.float32), node_types\n",
    "\n",
    "def simulate(adj, joints, node_types):\n",
    "    \"\"\"Run simulation with error handling\"\"\"\n",
    "    try:\n",
    "        if adj.dtype != np.float32:\n",
    "            adj = adj.astype(np.float32)\n",
    "        if joints.dtype != np.float32:\n",
    "            joints = joints.astype(np.float32)\n",
    "        \n",
    "        result = simulate_mechanism(adj, joints, node_types)\n",
    "        if result is None:\n",
    "            return None\n",
    "        \n",
    "        trajectory = torch.tensor(result[-1], dtype=torch.float32).unsqueeze(0)\n",
    "        return preprocess_curves(trajectory).detach().cpu().numpy().squeeze()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_joints(pred_sequence):\n",
    "    \"\"\"Prepare joint positions from single decoder output\"\"\"\n",
    "    # Remove start token and EOS token if present\n",
    "    joints = pred_sequence[1:].detach().cpu().float()\n",
    "    return np.concatenate([Config.prefix_rows, joints.numpy()], axis=0)\n",
    "\n",
    "def save_plot(ax, curve_dir, filename, title=None):\n",
    "    \"\"\"Helper function to save plots with guaranteed cleanup\"\"\"\n",
    "    try:\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.axis('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(curve_dir, filename))\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "def filter_invalid_joints(joints: np.ndarray, invalid_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Remove any row in `joints` that exactly matches any row in `invalid_values`.\"\"\"\n",
    "    mask = np.ones(len(joints), dtype=bool)\n",
    "    for invalid in invalid_values:\n",
    "        mask &= ~np.all(joints == invalid, axis=1)\n",
    "    return joints[mask]\n",
    "\n",
    "def create_curve_plot(ax, truth_joints, pred_joints, gt_curve=None, pred_curve=None, \n",
    "                     cond_curve=None, title=None):\n",
    "    \"\"\"Create a standardized plot with joint enumeration\"\"\"\n",
    "    try:\n",
    "        if gt_curve is not None:\n",
    "            ax.plot(gt_curve[:, 0], gt_curve[:, 1], **Config.plt_style['truth_curve'])\n",
    "        if pred_curve is not None:\n",
    "            ax.plot(pred_curve[:, 0], pred_curve[:, 1], **Config.plt_style['pred_curve'])\n",
    "        if cond_curve is not None:\n",
    "            ax.plot(cond_curve[:, 0], cond_curve[:, 1], **Config.plt_style['cond_curve'])\n",
    "        \n",
    "        # Scatter points\n",
    "        ax.scatter(truth_joints[:, 0], truth_joints[:, 1], **Config.plt_style['truth_joints'])\n",
    "        ax.scatter(pred_joints[:, 0], pred_joints[:, 1], **Config.plt_style['pred_joints'])\n",
    "\n",
    "        # Annotate truth joints\n",
    "        for idx, (x, y) in enumerate(truth_joints):\n",
    "            ax.annotate(str(idx), (x, y), textcoords=\"offset points\", xytext=(5,5), fontsize=8, color=\"red\")\n",
    "\n",
    "        # Annotate predicted joints\n",
    "        for idx, (x, y) in enumerate(pred_joints):\n",
    "            ax.annotate(str(idx), (x, y), textcoords=\"offset points\", xytext=(5,-10), fontsize=8, color=\"blue\")\n",
    "\n",
    "        if title:\n",
    "            ax.set_title(title)\n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Main processing\n",
    "prepare_results_dir()\n",
    "unique_adjs = np.load(\"unique_adjacency_matrices.npy\")\n",
    "print(f\"Loaded {len(unique_adjs)} unique adjacency matrices\")\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "    if batch_idx == 10:\n",
    "        break\n",
    "\n",
    "    # Create subfolder for this curve\n",
    "    curve_dir = os.path.join(Config.results_dir, f'curve_{batch_idx}')\n",
    "    os.makedirs(curve_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare data\n",
    "    curve_data = batch[\"curve_numerical\"].to(device).float()\n",
    "    gt_adj = batch[\"adjacency\"].to(device).float()\n",
    "\n",
    "    # Get ground truth joints from single label sequence\n",
    "    truth_joints = batch[\"label\"].view(-1, 2)[:-1].detach().cpu().float()  # Remove EOS token\n",
    "    truth_joints = np.concatenate([Config.prefix_rows, truth_joints.numpy()], axis=0)\n",
    "    \n",
    "    # Process ground truth adjacency\n",
    "    gt_adj_processed, gt_node_types = process_adjacency(gt_adj)\n",
    "\n",
    "    # Get prediction with ground truth adjacency\n",
    "    with torch.no_grad():\n",
    "        pred_sequence, curve_emb, adj_emb = greedy_decode_conditional(\n",
    "            model, curve_data, gt_adj, Config.max_mech_size\n",
    "        )\n",
    "    pred_joints = get_joints(pred_sequence)\n",
    "\n",
    "    # Filter out invalid joints\n",
    "    pred_joints = filter_invalid_joints(pred_joints, INVALID_JOINTS)\n",
    "    truth_joints = filter_invalid_joints(truth_joints, INVALID_JOINTS)\n",
    "\n",
    "    curve_emb = F.normalize(curve_emb, p=2, dim=-1)\n",
    "    adj_emb   = F.normalize(adj_emb, p=2, dim=-1)\n",
    "\n",
    "    # similarity = (curve_emb[0] @ adj_emb[0].t()).diagonal()\n",
    "    sim_val = F.cosine_similarity(curve_emb.view(1, -1), adj_emb.view(1, -1)).item()\n",
    "\n",
    "    # Run simulations\n",
    "    gt_curve = simulate(gt_adj_processed, truth_joints, gt_node_types)\n",
    "    pred_curve = simulate(gt_adj_processed, pred_joints, gt_node_types)\n",
    "    \n",
    "    # Plot 1: Ground Truth vs Prediction with GT Adjacency\n",
    "    with managed_figure() as ax:\n",
    "        create_curve_plot(\n",
    "            ax, truth_joints, pred_joints,\n",
    "            gt_curve=gt_curve, pred_curve=pred_curve,\n",
    "            title=f'Curve {batch_idx}: GT vs Pred (sim={sim_val:.4f})'\n",
    "        )\n",
    "        save_plot(ax, curve_dir, f'gt_vs_pred_sim_{sim_val:.4f}.png')\n",
    "    \n",
    "    for cond_idx, cond_adj in enumerate(unique_adjs[:Config.num_conditions]):\n",
    "        cond_adj_tensor = torch.from_numpy(cond_adj).to(device).float().unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            cond_sequence, cond_curve_emb, cond_adj_emb = greedy_decode_conditional(\n",
    "                model, curve_data, cond_adj_tensor, Config.max_mech_size\n",
    "            )\n",
    "\n",
    "        cond_joints = get_joints(cond_sequence)\n",
    "        cond_joints = filter_invalid_joints(cond_joints, INVALID_JOINTS)\n",
    "        cond_adj_processed, cond_node_types = process_adjacency(cond_adj)\n",
    "        cond_curve = simulate(cond_adj_processed, cond_joints, cond_node_types)\n",
    "        \n",
    "        if cond_curve is None:\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "        cond_curve_emb = F.normalize(cond_curve_emb, p=2, dim=-1)\n",
    "        cond_adj_emb = F.normalize(cond_adj_emb, p=2, dim=-1)\n",
    "\n",
    "        cond_sim_val = F.cosine_similarity(cond_curve_emb.view(1, -1), cond_adj_emb.view(1, -1)).item()\n",
    "        # cond_sim_val = similarity.mean().item()\n",
    "\n",
    "        with managed_figure() as ax:\n",
    "            create_curve_plot(\n",
    "                ax, truth_joints, cond_joints,\n",
    "                gt_curve=gt_curve, cond_curve=cond_curve,\n",
    "                title=f'Curve {batch_idx} Cond {cond_idx} (sim={cond_sim_val:.4f})'\n",
    "            )\n",
    "            save_plot(ax, curve_dir, f'condition_{cond_idx}_sim_{cond_sim_val:.4f}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Track unique matrices and their counts\n",
    "# unique_matrices = {}  # {hash_key: (matrix, count)}\n",
    "# counts = defaultdict(int)\n",
    "\n",
    "# for batch in tqdm(data_loader):\n",
    "#     gt_adj = batch[\"adjacency\"].float().cpu()  # Original matrices\n",
    "    \n",
    "#     for matrix in gt_adj:\n",
    "#         # Convert to numpy and create hashable key\n",
    "#         np_matrix = matrix.numpy()\n",
    "#         matrix_key = tuple(np_matrix.round(4).flatten())  # Round to avoid float precision issues\n",
    "        \n",
    "#         # Store first occurrence and count\n",
    "#         if matrix_key not in unique_matrices:\n",
    "#             unique_matrices[matrix_key] = np_matrix\n",
    "#         counts[matrix_key] += 1\n",
    "\n",
    "# # Save all unique matrices in one file\n",
    "# all_matrices = np.stack(list(unique_matrices.values()))\n",
    "# np.save(\"unique_adjacency_matrices.npy\", all_matrices)\n",
    "\n",
    "# print(f\"Saved {len(unique_matrices)} unique matrices\")\n",
    "# print(f\"Output shape: {all_matrices.shape}\")  # e.g. (25, 10, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
